# RobotRaider
Finds disallowed pages in robots.txt, and visits them using a browser
